<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <link rel="alternate" type="text/html" href="http://localhost:1313/"/>
    <title>Media Proxy on Tekion IT Status Page</title>
    <link>http://localhost:1313/affected/media-proxy/</link>
    <description>Incident history</description>
    <generator>github.com/cstate</generator>
    <language>en</language>
    
    <lastBuildDate>2018-04-25T04:13:00+00:00</lastBuildDate>
    <updated>2018-04-25T04:13:00+00:00</updated>
    
    
    
      <atom:link href="http://localhost:1313/affected/media-proxy/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>[Resolved] IPSec Connections</title>
        <link>http://localhost:1313/issues/2018-05-25-us-east-conn-issues/</link>
        <pubDate>Wed, 25 Apr 2018 04:13:00 +0000</pubDate>
        <guid>http://localhost:1313/issues/2018-05-25-us-east-conn-issues/</guid>
        <category>2018-04-25 04:13:59</category>
        <description>&lt;p&gt;&lt;strong&gt;Resolved&lt;/strong&gt; - &lt;em&gt;2018-05-25 05:54:00&lt;/em&gt;
We believe all users experiencing issues have been able to connect at this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Monitoring&lt;/strong&gt; - &lt;em&gt;2018-05-25 04:40:00&lt;/em&gt;
We believe the connectivity issues are being caused by an isolated ISP issue. We&amp;rsquo;ve had reports that swapping to Google DNS servers resolves the problem for users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investigating&lt;/strong&gt; - &lt;em&gt;2018-05-25 04:13:00&lt;/em&gt;
We&amp;rsquo;re aware of reports that users are experiencing connection issues on the East coast of the United States. We&amp;rsquo;re currently investigating these issues, and apologize for any inconvenience it may be causing you.&lt;/p&gt;</description>
        <content type="html">&lt;p&gt;&lt;strong&gt;Resolved&lt;/strong&gt; - &lt;em&gt;2018-05-25 05:54:00&lt;/em&gt;
We believe all users experiencing issues have been able to connect at this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Monitoring&lt;/strong&gt; - &lt;em&gt;2018-05-25 04:40:00&lt;/em&gt;
We believe the connectivity issues are being caused by an isolated ISP issue. We&amp;rsquo;ve had reports that swapping to Google DNS servers resolves the problem for users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investigating&lt;/strong&gt; - &lt;em&gt;2018-05-25 04:13:00&lt;/em&gt;
We&amp;rsquo;re aware of reports that users are experiencing connection issues on the East coast of the United States. We&amp;rsquo;re currently investigating these issues, and apologize for any inconvenience it may be causing you.&lt;/p&gt;
</content>
      </item>
    
      <item>
        <title>[Resolved] Unavailable Guilds &amp; Connection Issues</title>
        <link>http://localhost:1313/issues/2018-04-13-unavailable-guilds-connection-issues/</link>
        <pubDate>Sat, 14 Apr 2018 15:54:00 +0000</pubDate>
        <guid>http://localhost:1313/issues/2018-04-13-unavailable-guilds-connection-issues/</guid>
        <category>2018-04-13 17:30:00</category>
        <description>&lt;p&gt;&lt;em&gt;Post-mortem&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At approximately 14:01, a Redis instance acting as the primary for a highly-available cluster used by our API services was migrated automatically by Google’s Cloud Platform. This migration caused the node to incorrectly drop offline, forcing the cluster to rebalance and trigger known issues with the way our API instances handle Redis failover. After resolving this partial outage, unnoticed issues on other services caused a cascading failure through Example Chat App’s real time system. These issues caused enough critical impact that Example Chat App’s engineering team was forced to fully restart the service, reconnecting millions of clients over a period of 20 minutes.&lt;/p&gt;</description>
        <content type="html">&lt;p&gt;&lt;em&gt;Post-mortem&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;At approximately 14:01, a Redis instance acting as the primary for a highly-available cluster used by our API services was migrated automatically by Google’s Cloud Platform. This migration caused the node to incorrectly drop offline, forcing the cluster to rebalance and trigger known issues with the way our API instances handle Redis failover. After resolving this partial outage, unnoticed issues on other services caused a cascading failure through Example Chat App’s real time system. These issues caused enough critical impact that Example Chat App’s engineering team was forced to fully restart the service, reconnecting millions of clients over a period of 20 minutes.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; - &lt;em&gt;2018-04-13 17:30:00&lt;/em&gt;
A fix has been implemented and we are monitoring the results. Looks like this has been fixed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Monitoring&lt;/strong&gt; - &lt;em&gt;2018-04-13 16:50:00&lt;/em&gt;
After hitting the ole reboot button Example Chat App is now recovering. We&amp;rsquo;re going to continue to monitor as everyone reconnects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investigating&lt;/strong&gt; - &lt;em&gt;2018-04-13 15:54:00&lt;/em&gt;
We&amp;rsquo;re aware of users experiencing unavailable guilds and issues when attempting to connect. We&amp;rsquo;re currently investigating.&lt;/p&gt;
</content>
      </item>
    
  </channel>
</rss>
